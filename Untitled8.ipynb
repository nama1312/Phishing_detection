{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5380c4-fa88-41b4-aad3-271142fb4d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d6469c-117f-4f89-9341-69898371a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91b8dfab-45a2-4736-9c81-a59042ddf895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'url_length', 'number_of_dots_in_url',\n",
       "       'having_repeated_digits_in_url', 'number_of_digits_in_url',\n",
       "       'number_of_special_char_in_url', 'number_of_hyphens_in_url',\n",
       "       'number_of_underline_in_url', 'number_of_slash_in_url',\n",
       "       'number_of_questionmark_in_url', 'number_of_equal_in_url',\n",
       "       'number_of_at_in_url', 'number_of_dollar_in_url',\n",
       "       'number_of_exclamation_in_url', 'number_of_hashtag_in_url',\n",
       "       'number_of_percent_in_url', 'domain_length', 'number_of_dots_in_domain',\n",
       "       'number_of_hyphens_in_domain', 'having_special_characters_in_domain',\n",
       "       'number_of_special_characters_in_domain', 'having_digits_in_domain',\n",
       "       'number_of_digits_in_domain', 'having_repeated_digits_in_domain',\n",
       "       'number_of_subdomains', 'having_dot_in_subdomain',\n",
       "       'having_hyphen_in_subdomain', 'average_subdomain_length',\n",
       "       'average_number_of_dots_in_subdomain',\n",
       "       'average_number_of_hyphens_in_subdomain',\n",
       "       'having_special_characters_in_subdomain',\n",
       "       'number_of_special_characters_in_subdomain',\n",
       "       'having_digits_in_subdomain', 'number_of_digits_in_subdomain',\n",
       "       'having_repeated_digits_in_subdomain', 'having_path', 'path_length',\n",
       "       'having_query', 'having_fragment', 'having_anchor', 'entropy_of_url',\n",
       "       'entropy_of_domain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e561ab6e-2d44-4d3d-b9c2-b855bdeb4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff67faf-71a2-4395-8aa2-55776f249584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tldextract\n",
    "\n",
    "\n",
    "def extract_features(url):\n",
    "    # URL length\n",
    "    url_length = len(url)\n",
    "\n",
    "    # Number of dots in URL\n",
    "    number_of_dots_in_url = url.count('.')\n",
    "\n",
    "    # Having repeated digits in URL\n",
    "    having_repeated_digits_in_url = 1 if re.search(r'(\\d)\\1{2,}', url) else 0\n",
    "\n",
    "    # Number of digits in URL\n",
    "    number_of_digits_in_url = len(re.findall(r'\\d', url))\n",
    "\n",
    "    # Number of special characters in URL\n",
    "    number_of_special_char_in_url = len(re.findall(r'[!@#$%^&*(),.?\":{}|<>]', url))\n",
    "\n",
    "    # Number of hyphens in URL\n",
    "    number_of_hyphens_in_url = url.count('-')\n",
    "\n",
    "    # Number of underscores in URL\n",
    "    number_of_underline_in_url = url.count('_')\n",
    "\n",
    "    # Number of slashes in URL\n",
    "    number_of_slash_in_url = url.count('/')\n",
    "\n",
    "    # Number of question marks in URL\n",
    "    number_of_questionmark_in_url = url.count('?')\n",
    "\n",
    "    # Number of equal signs in URL\n",
    "    number_of_equal_in_url = url.count('=')\n",
    "\n",
    "    # Number of at signs in URL\n",
    "    number_of_at_in_url = url.count('@')\n",
    "\n",
    "    # Number of dollar signs in URL\n",
    "    number_of_dollar_in_url = url.count('$')\n",
    "\n",
    "    # Number of exclamation marks in URL\n",
    "    number_of_exclamation_in_url = url.count('!')\n",
    "\n",
    "    # Number of hashtags in URL\n",
    "    number_of_hashtag_in_url = url.count('#')\n",
    "\n",
    "    # Number of percent signs in URL\n",
    "    number_of_percent_in_url = url.count('%')\n",
    "\n",
    "    # Extract domain details\n",
    "    ext = tldextract.extract(url)\n",
    "    domain = ext.domain\n",
    "    subdomain = ext.subdomain\n",
    "\n",
    "    # Domain length\n",
    "    domain_length = len(domain)\n",
    "\n",
    "    # Number of dots in domain\n",
    "    number_of_dots_in_domain = domain.count('.')\n",
    "\n",
    "    # Number of hyphens in domain\n",
    "    number_of_hyphens_in_domain = domain.count('-')\n",
    "\n",
    "    # Having special characters in domain\n",
    "    having_special_characters_in_domain = 1 if re.search(r'[!@#$%^&*(),.?\":{}|<>]', domain) else 0\n",
    "\n",
    "    # Number of special characters in domain\n",
    "    number_of_special_characters_in_domain = len(re.findall(r'[!@#$%^&*(),.?\":{}|<>]', domain))\n",
    "\n",
    "    # Having digits in domain\n",
    "    having_digits_in_domain = 1 if re.search(r'\\d', domain) else 0\n",
    "\n",
    "    # Number of digits in domain\n",
    "    number_of_digits_in_domain = len(re.findall(r'\\d', domain))\n",
    "\n",
    "    # Having repeated digits in domain\n",
    "    having_repeated_digits_in_domain = 1 if re.search(r'(\\d)\\1{2,}', domain) else 0\n",
    "\n",
    "    # Number of subdomains\n",
    "    number_of_subdomains = len(subdomain.split('.'))\n",
    "\n",
    "    # Having dot in subdomain\n",
    "    having_dot_in_subdomain = 1 if '.' in subdomain else 0\n",
    "\n",
    "    # Having hyphen in subdomain\n",
    "    having_hyphen_in_subdomain = 1 if '-' in subdomain else 0\n",
    "\n",
    "    # Average subdomain length\n",
    "    average_subdomain_length = np.mean([len(part) for part in subdomain.split('.')])\n",
    "\n",
    "    # Average number of dots in subdomain\n",
    "    average_number_of_dots_in_subdomain = number_of_dots_in_url / number_of_subdomains if number_of_subdomains > 0 else 0\n",
    "\n",
    "    # Average number of hyphens in subdomain\n",
    "    average_number_of_hyphens_in_subdomain = number_of_hyphens_in_url / number_of_subdomains if number_of_subdomains > 0 else 0\n",
    "\n",
    "    # Having special characters in subdomain\n",
    "    having_special_characters_in_subdomain = 1 if re.search(r'[!@#$%^&*(),.?\":{}|<>]', subdomain) else 0\n",
    "\n",
    "    # Number of special characters in subdomain\n",
    "    number_of_special_characters_in_subdomain = len(re.findall(r'[!@#$%^&*(),.?\":{}|<>]', subdomain))\n",
    "\n",
    "    # Having digits in subdomain\n",
    "    having_digits_in_subdomain = 1 if re.search(r'\\d', subdomain) else 0\n",
    "\n",
    "    # Number of digits in subdomain\n",
    "    number_of_digits_in_subdomain = len(re.findall(r'\\d', subdomain))\n",
    "\n",
    "    # Having repeated digits in subdomain\n",
    "    having_repeated_digits_in_subdomain = 1 if re.search(r'(\\d)\\1{2,}', subdomain) else 0\n",
    "\n",
    "    # Check if URL has a path\n",
    "    path = url.split(domain)[-1] if domain in url else \"\"\n",
    "    having_path = 1 if path else 0\n",
    "    path_length = len(path)\n",
    "\n",
    "    # Check if URL has a query\n",
    "    having_query = 1 if '?' in url else 0\n",
    "\n",
    "    # Check if URL has a fragment\n",
    "    having_fragment = 1 if '#' in url else 0\n",
    "\n",
    "    # Check if URL has an anchor\n",
    "    having_anchor = 1 if '#' in url else 0\n",
    "\n",
    "    # Entropy calculations\n",
    "    def calculate_entropy(string):\n",
    "        probabilities = [float(string.count(c)) / len(string) for c in dict.fromkeys(list(string))]\n",
    "        entropy = - sum([p * np.log2(p) for p in probabilities])\n",
    "        return entropy\n",
    "\n",
    "    entropy_of_url = calculate_entropy(url)\n",
    "    entropy_of_domain = calculate_entropy(domain)\n",
    "\n",
    "    # Return features as a list\n",
    "    return [\n",
    "        url_length, number_of_dots_in_url, having_repeated_digits_in_url,\n",
    "        number_of_digits_in_url, number_of_special_char_in_url, number_of_hyphens_in_url,\n",
    "        number_of_underline_in_url, number_of_slash_in_url, number_of_questionmark_in_url,\n",
    "        number_of_equal_in_url, number_of_at_in_url, number_of_dollar_in_url,\n",
    "        number_of_exclamation_in_url, number_of_hashtag_in_url, number_of_percent_in_url,\n",
    "        domain_length, number_of_dots_in_domain, number_of_hyphens_in_domain,\n",
    "        having_special_characters_in_domain, number_of_special_characters_in_domain,\n",
    "        having_digits_in_domain, number_of_digits_in_domain, having_repeated_digits_in_domain,\n",
    "        number_of_subdomains, having_dot_in_subdomain, having_hyphen_in_subdomain,\n",
    "        average_subdomain_length, average_number_of_dots_in_subdomain,\n",
    "        average_number_of_hyphens_in_subdomain, having_special_characters_in_subdomain,\n",
    "        number_of_special_characters_in_subdomain, having_digits_in_subdomain,\n",
    "        number_of_digits_in_subdomain, having_repeated_digits_in_subdomain, having_path,\n",
    "        path_length, having_query, having_fragment, having_anchor,\n",
    "        entropy_of_url, entropy_of_domain\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "233b0fce-c77d-4cd3-9416-2f24affdcb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96     38569\n",
      "           1       0.97      0.95      0.96     35816\n",
      "\n",
      "    accuracy                           0.96     74385\n",
      "   macro avg       0.96      0.96      0.96     74385\n",
      "weighted avg       0.96      0.96      0.96     74385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('Dataset.csv')\n",
    "\n",
    "\n",
    "# Data preprocessing\n",
    "X = data.drop('Type', axis=1)\n",
    "y = data['Type']\n",
    "\n",
    "# Handle missing values if any\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model preparation\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab8cb8a-b22f-4a79-8cfc-b1d64d2cb35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remaining samples after outlier removal: 0\n",
    "#All samples were removed by the outlier detection. Consider relaxing the filtering criteria.\n",
    "\n",
    "#hence didnot provided outlier treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0bae0d6-068e-47e1-a1a5-1915a9eddb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model and scaler\n",
    "joblib.dump(model, 'phishing_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca41f42-12fb-4291-b759-61fc5670f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "#  LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f094c9-774d-4c2e-b6e3-64219fbead8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('Dataset.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X = data.drop('Type', axis=1)\n",
    "y = data['Type']\n",
    "\n",
    "# If the target variable 'Type' is categorical, convert it to numeric values\n",
    "# using LabelEncoder if not done already\n",
    "if y.dtype == 'object' or y.dtype == 'category':\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Handle missing values if any\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model preparation using Logistic Regression\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, print accuracy as well\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908d4377-db10-4609-8c73-55cd49bd008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "\n",
    "##########\n",
    "\n",
    "#### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3172a7c-bec2-4e8d-ba82-54ecf1d98883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     38569\n",
      "           1       0.95      0.94      0.94     35816\n",
      "\n",
      "    accuracy                           0.95     74385\n",
      "   macro avg       0.95      0.95      0.95     74385\n",
      "weighted avg       0.95      0.95      0.95     74385\n",
      "\n",
      "Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('Dataset.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X = data.drop('Type', axis=1)\n",
    "y = data['Type']\n",
    "\n",
    "# If the target variable 'Type' is categorical, convert it to numeric values\n",
    "# using LabelEncoder if not done already\n",
    "if y.dtype == 'object' or y.dtype == 'category':\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Handle missing values if any\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Feature scaling is optional for Decision Trees but I am keeping it consistent\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model preparation using Decision Tree Classifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, print accuracy as well\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0511aff-f568-4c2a-9a71-edaf6e408267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84     38569\n",
      "           1       0.87      0.73      0.79     35816\n",
      "\n",
      "    accuracy                           0.82     74385\n",
      "   macro avg       0.83      0.81      0.81     74385\n",
      "weighted avg       0.82      0.82      0.82     74385\n",
      "\n",
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Example of tuning max depth\n",
    "modelll = DecisionTreeClassifier(max_depth=5, random_state=42)  # Limiting the depth to 5\n",
    "modelll.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# Predictions\n",
    "y_pred = modelll.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, print accuracy as well\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "710cfd74-42df-4ba5-9596-e808f786ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "\n",
    "#########SVM ################\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb0b68-10e3-466f-9889-4db4cb481ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('Dataset.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X = data.drop('Type', axis=1)\n",
    "y = data['Type']\n",
    "\n",
    "# If the target variable 'Type' is categorical, convert it to numeric values\n",
    "# using LabelEncoder if not done already\n",
    "if y.dtype == 'object' or y.dtype == 'category':\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Handle missing values if any\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Feature scaling is crucial for SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model preparation using Support Vector Classifier (SVC)\n",
    "model = SVC(kernel='linear', random_state=42)  # Using linear kernel\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, print accuracy as well\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e33ab-b4c8-4487-9235-f0d4ad1c6456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
